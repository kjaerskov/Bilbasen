---
title: "Scrape an used car website and select a fair priced car using Random Forest"
author: "Frederik Holmelund Kjærskov"
date: "3 March 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Scraping an used car site - part II

As mentioned in [this post](https://r-tify.blogspot.dk/2018/03/a-web-scraper-for-bilbasendk.html) I built a web scraper for an used car site to practice web scraping skills. This time we go ahead and apply this scraper, collect used car data and train and apply a Random Forest algorithm to predict used car prices. As a bonus, we will interpretate the results from the Random Forest to select a fairly priced car. Remember, I did think about buying a car in a near future. 

Because the scraper itself is explained in [my previous post](https://r-tify.blogspot.dk/2018/03/a-web-scraper-for-bilbasendk.html) I will simply just source it in addition to loading the necessary libraries. It sources all VW from 2010 to 2018 currently on sale at bilbasen.dk. 
```{r warning=FALSE, message=FALSE}
library('ggplot2') # visualization
library('scales') # visualization
library('dplyr') # data manipulation
library('randomForest') # classification algorithm

source("CrawlBilbasen.r") # Source the web scraping script
summary(df)
```
See that there are a few entries that contains NAs. For this example, we will not spend time performing imputation and substitute missing values hence we simply omit all NA entries. 

```{r}
#Remove rows with n.a. data
df <- na.omit(df)
```

## Build the model

Now we got the data we need. Next is to train our Random Forest algorithm for us to predict used car prices. We therefore divide our data into two sets. A training data set and a test data set. There are ways to do this clever but for matters of simplicity we denote two thirds of the data as training data and the remaining third as test data. To subset the data we first reorder the data randomly and select the dimensions we wish to model on. In this case we will train our model using model name, year, engine size, horsepower, number of doors, mileage, consumption and region where the car is on sale. All these dimensions seem plausible in determining the car price. 

```{r}
#Randomize order for us to split data set into training and test sets
set.seed(666) # I like heavy metal
dfmodel <- df[sample(nrow(df),nrow(df)),c("URL", "Model", "Year", "Engine", "Horsepower", "Doors" ,"Price","Mileage","Consumption", "Region")]

#Train using two thirds of the dataset, test using the last third
trainingData <- dfmodel[1:ceiling(nrow(df)*(2/3)),]
testData <- dfmodel[1:floor(nrow(df)*(1/3)),]
```

And here comes the modelling. We use the Random Forest algorithm to perform regression on price given the dimensions and training data just mentioned and hence write:

```{r}
# Build the model using the specified variables
rfModelPrice <- randomForest(Price ~ Year + Engine + Mileage + Consumption + Doors + Horsepower + Model + Region, data = trainingData)

```

And the model is built. Now, 